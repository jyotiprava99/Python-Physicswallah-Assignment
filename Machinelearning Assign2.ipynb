{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41e97741-8754-4ae9-9b8d-5f38e26d784e",
   "metadata": {},
   "source": [
    "Q1: Define overfitting and underfitting in machine learning. What are the consequences of each, and how\n",
    "can they be mitigated?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28c613b-0719-4b9d-b8b9-1fde18d0dbbd",
   "metadata": {},
   "source": [
    "Ans: In machine learning, overfitting happens when a model is too complex and learns the training data too well, but struggles to generalize to new data. \n",
    "The consequence is that the model performs really well on the training data, but poorly on unseen data.\n",
    "On the other hand, underfitting occurs when a model is too simple and fails to capture the underlying patterns in the data.\n",
    "The consequence is that the model performs poorly on both the training data and unseen data.\n",
    "To mitigate overfitting, you can try techniques like regularization, which adds a penalty for complexity , or using more training data.\n",
    "For underfitting, you can try using a more relevant features or increasing the"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dd7f1d-6325-4ab8-993d-e2597e82750b",
   "metadata": {},
   "source": [
    "\n",
    "Q2: How can we reduce overfitting? Explain in brief.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62d36c7-b9fe-4971-bd22-c16b38533c44",
   "metadata": {},
   "source": [
    "Ans: To reduce overfitting in machine learning, you can try a few techniques. One common approach is to use for regularization, which adds a penalty for complexity \n",
    " to the model during training. This helps prevent the model from lifting the training data too closely.\n",
    "Another method is to increase the amount of training data. More data can provide a better representation of the underlying patterns in the data,\n",
    "reducing the chances of overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f12743-14ba-42b5-94bd-e5ef84a29e2c",
   "metadata": {},
   "source": [
    "\n",
    "Q3: Explain underfitting. List scenarios where underfitting can occur in ML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9355f467-ab28-4079-b32b-ddefb3d9e577",
   "metadata": {},
   "source": [
    "Ans: Underfitting occurs when a machine learning model is too simple or lacks complexity to capture the underlying patterns in the data.\n",
    "It results in poor performance on both the training data and unseen data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7209f7a-bdcd-463d-a701-98f647e251e2",
   "metadata": {},
   "source": [
    "Q4: Explain the bias-variance tradeoff in machine learning. What is the relationship between bias and\n",
    "variance, and how do they affect model performance?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ec19c4-0396-4ac3-a0be-7f8c1633ddde",
   "metadata": {},
   "source": [
    "Ans: The bias-variance tradeoff is an important concept in machine learning. It refers to balance between a model's ability to capture the underlying patterns in the data (bias) and its sensitivity to variations in the data(variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69baa901-4f5f-4af1-82e5-897312f2e0bb",
   "metadata": {},
   "source": [
    "\n",
    "Q5: Discuss some common methods for detecting overfitting and underfitting in machine learning models.\n",
    "How can you determine whether your model is overfitting or underfitting?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f680e3-c5eb-4d69-862b-78f6c30fb46e",
   "metadata": {},
   "source": [
    "1: Training and Validation Curves: Plotting the model's performance on both the training and validation datasets can provide insights. If the training accuracy continues to improve while the validation\n",
    "accuracy plateaus or decreases, it may indicate overfitting. Conversely ,if both accuracies are low, it may suggest underfitting.\n",
    "\n",
    "2: Cross-validation: By using techniques like k-fold cross-validation, you can evaluate the model's performance on multiple subsets of the data. If the model performs well on the training data but poorly on the vlidation sets, it could be overfitting.\n",
    "3:Learning curves: Learning curves show the model's performance as a function of training set size. If the training and validation errors converge at a high value, it may indicate underfitting. If there is a large gap between the two errors, it may suggest overfitting.\n",
    "\n",
    "4: Regularisation: Applying regularisation techniques such as L1 or L2 regularisation can help control overfittiong.\n",
    "If the model's performance improves with regularisation, it suggests that overfitting was present.\n",
    "\n",
    "5: Error Analysis: Analysing the model's errors can provide insights into overfitting or underfitting. If the model is consistently misclassifying certain types of examples, it may indicate underfitting.If it is overly confident in its predictions and makes mistakes on similar examples, it may suggest overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4c22e1-6884-4fd3-afb6-56e0ffe3c9ff",
   "metadata": {},
   "source": [
    "\n",
    "Q6: Compare and contrast bias and variance in machine learning. What are some examples of high bias\n",
    "and high variance models, and how do they differ in terms of their performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13d8b15-4f8e-4260-ac08-154735f02bee",
   "metadata": {},
   "source": [
    "Bias refers to the error that is introduced by the model's assumptions, simplifications or limitations.It represents the model's tendency to consistently\n",
    "underpredict or overpredict the true values. High bias models have a strong bias towards certain assumptions and may oversimplify the relationships in the data.\n",
    "They often result in uderfitting, where the model fails to capture the complexity of the data.\n",
    "\n",
    "On other hand, variance refers to the error that is introduced due to the model's sensitivity to fluctuations or noise in the training data.High variance models are very flexible and can fit the training data very closely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b549fdb-4a69-4cfd-a8fb-ae874af343fd",
   "metadata": {},
   "source": [
    "\n",
    "Q7: What is regularization in machine learning, and how can it be used to prevent overfitting? Describe\n",
    "some common regularization techniques and how they work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3567cbf0-6ec2-40c7-bf8c-b3aaa4551c28",
   "metadata": {},
   "source": [
    "Regulation in machine learning also known as regularisation, is a technique used to prevent overfitting in models becomes too complex and starts to memorise the training data instead of learning the underlying patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc78fb27-3e5e-4295-a2f8-68b7d89fb243",
   "metadata": {},
   "source": [
    "To prevent overfittng , regularisation introduces a penalty term to model's objective function. This penalty discourages the model from fitting the training data too closely and encourages it to generalize well to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437db4fe-a3c6-4284-bee8-3515bd0a7c14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
